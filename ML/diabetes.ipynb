{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[],"source":["from mlxtend.plotting import plot_decision_regions\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","sns.set()\n","import warnings\n","warnings.filterwarnings('ignore')\n","%matplotlib inline\n","#plt.style.use('ggplot')\n","#ggplot is R based visualisation package that provides better graphics with higher level of abstraction"]},{"cell_type":"markdown","metadata":{"_uuid":"fb40452ad5ae975fd33307735fd47c33f1aca999"},"source":["## Basic Data Science and ML Pipeline"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"3977359aa7f65cc9d96fdf0ede4e99116fb314c6","trusted":true},"outputs":[],"source":["#Loading the dataset\n","diabetes_data = pd.read_csv('../input/diabetes.csv')\n","\n","#Print the first 5 rows of the dataframe.\n","diabetes_data.head()"]},{"cell_type":"markdown","metadata":{"_uuid":"e19cd0e1959c38d52ed8c437b42f3ccd61e92fb4"},"source":["## Basic EDA and statistical analysis\n"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"650e7357fe6d26e6a557cc3088d9b1147b6093ea","scrolled":true,"trusted":true},"outputs":[],"source":["diabetes_data.info(verbose=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"0682a8c7acbdb75ad600df7b7cd732f4d5b0a17f","trusted":true},"outputs":[],"source":["diabetes_data.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"de488e0ee803ee6d4084c92df3f548eb6a051d43","trusted":true},"outputs":[],"source":["diabetes_data.describe().T"]},{"cell_type":"markdown","metadata":{"_uuid":"a5c66431403ac1246f52e4256b09b660fc273c25"},"source":["#### It is better to replace zeros with nan since after that counting them would be easier and zeros need to be replaced with suitable values"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"506fa58605d641694883cad75bb3683dafdb0356","trusted":true},"outputs":[],"source":["diabetes_data_copy = diabetes_data.copy(deep= True)\n","diabetes_data_copy[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']] = diabetes_data_copy[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']].replace(0,np.NaN)\n","\n","## showing the count of Nans\n","print(diabetes_data_copy.isnull().sum())"]},{"cell_type":"markdown","metadata":{"_uuid":"20bf4545b4d80cd00061d08d3cc2206d0b80f376","trusted":true},"source":["#### To fill these Nan values the data distribution needs to be understood"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"d5ef22db6afea0d63189599fb4abbb2b3f53ccb5","trusted":true},"outputs":[],"source":["p = diabetes_data.hist(figsize = (20,20))"]},{"cell_type":"markdown","metadata":{"_uuid":"337635cc5b94f7bf6b1a95f5d4043e67604c2c8a"},"source":["### Aiming to impute nan values for the columns in accordance with their distribution"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"0568a737f6529e711d3e1ffa5493f0fa749efff3","trusted":true},"outputs":[],"source":["diabetes_data_copy['Glucose'].fillna(diabetes_data_copy['Glucose'].mean(), inplace = True)\n","diabetes_data_copy['BloodPressure'].fillna(diabetes_data_copy['BloodPressure'].mean(), inplace = True)\n","diabetes_data_copy['SkinThickness'].fillna(diabetes_data_copy['SkinThickness'].median(), inplace = True)\n","diabetes_data_copy['Insulin'].fillna(diabetes_data_copy['Insulin'].median(), inplace = True)\n","diabetes_data_copy['BMI'].fillna(diabetes_data_copy['BMI'].median(), inplace = True)"]},{"cell_type":"markdown","metadata":{"_uuid":"1bf99a7a106d92072207b4a5071098ac32c03902"},"source":["## Plotting after Nan removal "]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"6b54f61be1a5b6fc75a90bfdcdfdb1df18a38594","trusted":true},"outputs":[],"source":["p = diabetes_data_copy.hist(figsize = (20,20))"]},{"cell_type":"markdown","metadata":{"_uuid":"fc09dd32d8cf836fd9afbb8f4d83d47260b89e91"},"source":["## Skewness\n","\n","A ***left-skewed distribution*** has a long left tail. Left-skewed distributions are also called negatively-skewed distributions. That‚Äôs because there is a long tail in the negative direction on the number line. The mean is also to the left of the peak.\n","\n","A ***right-skewed distribution*** has a long right tail. Right-skewed distributions are also called positive-skew distributions. That‚Äôs because there is a long tail in the positive direction on the number line. The mean is also to the right of the peak.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"8322614f5de4888d713c0468a43ae2a3eb1b8862","trusted":true},"outputs":[],"source":["## observing the shape of the data\n","diabetes_data.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"c69e3cf2bce422520047daa7b02b688e42c197e4","trusted":true},"outputs":[],"source":["## data type analysis\n","#plt.figure(figsize=(5,5))\n","#sns.set(font_scale=2)\n","sns.countplot(y=diabetes_data.dtypes ,data=diabetes_data)\n","plt.xlabel(\"count of each data type\")\n","plt.ylabel(\"data types\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"1d5a4e88b691d25e8c661e3e292f5d81d33c576e","trusted":true},"outputs":[],"source":["## null count analysis\n","import missingno as msno\n","p=msno.bar(diabetes_data)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"009e21b28bb9fcb64bd0b841d0aa09597b9bbea8","trusted":true},"outputs":[],"source":["## checking the balance of the data by plotting the count of outcomes by their value\n","color_wheel = {1: \"#0392cf\", \n","               2: \"#7bc043\"}\n","colors = diabetes_data[\"Outcome\"].map(lambda x: color_wheel.get(x + 1))\n","print(diabetes_data.Outcome.value_counts())\n","p=diabetes_data.Outcome.value_counts().plot(kind=\"bar\")\n"]},{"cell_type":"markdown","metadata":{"_uuid":"48fd3f1b1b8c38b94d06fb4a4daf4afd592beb15","trusted":true},"source":["#### The above graph shows that the data is biased towards datapoints having outcome value as 0 where it means that diabetes was not present actually. The number of non-diabetics is almost twice the number of diabetic patients"]},{"cell_type":"markdown","metadata":{"_uuid":"87dc25ce0f9036237af2b8fb8560d7ba575df22c"},"source":["#### Scatter matrix of uncleaned data"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"f100c23bcf63fa58180813ff594dfff591bb20ed","trusted":true},"outputs":[],"source":["from pandas.tools.plotting import scatter_matrix\n","p=scatter_matrix(diabetes_data,figsize=(25, 25))"]},{"cell_type":"markdown","metadata":{"_uuid":"47a5993e4001d4ffc0ddf2dd59740045048ba738"},"source":["#### Pair plot for clean data"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"3adefc9ab47271b11f13687a245df6ced9f1b312","trusted":true},"outputs":[],"source":["p=sns.pairplot(diabetes_data_copy, hue = 'Outcome')"]},{"cell_type":"markdown","metadata":{"_uuid":"108b278e68021929a5c8cd186afc4848f1767986","trusted":true},"source":["***Pearson's Correlation Coefficient***: helps you find out the relationship between two quantities. It gives you the measure of the strength of association between two variables. The value of Pearson's Correlation Coefficient can be between -1 to +1. 1 means that they are highly correlated and 0 means no correlation.\n","\n","A heat map is a two-dimensional representation of information with the help of colors. Heat maps can help the user visualize simple or complex information."]},{"cell_type":"markdown","metadata":{"_uuid":"9dbea8e64dd833ce466c5d0585f4d8ad5bbfe8ff"},"source":["#### Heatmap for unclean data"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"2971ad528058ac82e54eec7b42b814644cef4195","trusted":true},"outputs":[],"source":["plt.figure(figsize=(12,10))  # on this line I just set the size of figure to 12 by 10.\n","p=sns.heatmap(diabetes_data.corr(), annot=True,cmap ='RdYlGn')  # seaborn has very simple solution for heatmap"]},{"cell_type":"markdown","metadata":{"_uuid":"a97ddd37b576e90c5cc192bd8ab46a4d44c960af"},"source":["#### Heatmap for clean data"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"0b000ace1a6558c57c0b485c66a5bdb84063174b","trusted":true},"outputs":[],"source":["plt.figure(figsize=(12,10))  # on this line I just set the size of figure to 12 by 10.\n","p=sns.heatmap(diabetes_data_copy.corr(), annot=True,cmap ='RdYlGn')  # seaborn has very simple solution for heatmap"]},{"cell_type":"markdown","metadata":{"_uuid":"5e5142438fcc7973b722337deb24ba2061e14316"},"source":["## Scaling the data \n","data Z is rescaled such that Œº = 0 and ùõî = 1, and is done through this formula:"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"2cf6c9ff22d3a7af35e399406e7565055ca6af36","trusted":true},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\n","sc_X = StandardScaler()\n","X =  pd.DataFrame(sc_X.fit_transform(diabetes_data_copy.drop([\"Outcome\"],axis = 1),),\n","        columns=['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n","       'BMI', 'DiabetesPedigreeFunction', 'Age'])"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"e10c79fe13861fb0fbe714c977f93bb8ed90a5fd","trusted":true},"outputs":[],"source":["X.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"9d9bd9ecd9612fb32f0629a8a3c0a85a14b034cf","trusted":true},"outputs":[],"source":["#X = diabetes_data.drop(\"Outcome\",axis = 1)\n","y = diabetes_data_copy.Outcome"]},{"cell_type":"markdown","metadata":{},"source":["### Why Scaling the data for KNN?"]},{"cell_type":"markdown","metadata":{},"source":["#### it is always advisable to bring all the features to the same scale for applying distance based algorithms like KNN.\n","##### Let's see an example of distance calculation using two features whose magnitudes/ranges vary greatly.\n","Euclidean Distance = [(100000‚Äì80000)^2 + (30‚Äì25)^2]^(1/2)"]},{"cell_type":"markdown","metadata":{},"source":["#### We can imagine how the feature with greater range with overshadow or dimenish the smaller feature completely and this will impact the performance of all distance based model as it will give higher weightage to variables which have higher magnitude."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"f14c88ae0a061de30566d336608d195ba89993d9","trusted":true},"outputs":[],"source":["#importing train_test_split\n","from sklearn.model_selection import train_test_split\n","X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=1/3,random_state=42, stratify=y)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"a7081050c51df07b8af1cd18c9be61f041a97fb8","trusted":true},"outputs":[],"source":["from sklearn.neighbors import KNeighborsClassifier\n","\n","\n","test_scores = []\n","train_scores = []\n","\n","for i in range(1,15):\n","\n","    knn = KNeighborsClassifier(i)\n","    knn.fit(X_train,y_train)\n","    \n","    train_scores.append(knn.score(X_train,y_train))\n","    test_scores.append(knn.score(X_test,y_test))"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"ee126a72ca24e54ee78bfac94a21dfac1a3edee1","trusted":true},"outputs":[],"source":["## score that comes from testing on the same datapoints that were used for training\n","max_train_score = max(train_scores)\n","train_scores_ind = [i for i, v in enumerate(train_scores) if v == max_train_score]\n","print('Max train score {} % and k = {}'.format(max_train_score*100,list(map(lambda x: x+1, train_scores_ind))))"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"8bbfda9d066c354f974dcb1180c3348aaa915c4e","trusted":true},"outputs":[],"source":["## score that comes from testing on the datapoints that were split in the beginning to be used for testing solely\n","max_test_score = max(test_scores)\n","test_scores_ind = [i for i, v in enumerate(test_scores) if v == max_test_score]\n","print('Max test score {} % and k = {}'.format(max_test_score*100,list(map(lambda x: x+1, test_scores_ind))))"]},{"cell_type":"markdown","metadata":{"_uuid":"fe08768381ea8011d90ae58149c8e41b0a707da2"},"source":["## Result Visualisation"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"2a5c0b4fde15148a049fa340a58f5b4fa421e614","trusted":true},"outputs":[],"source":["plt.figure(figsize=(12,5))\n","p = sns.lineplot(range(1,15),train_scores,marker='*',label='Train Score')\n","p = sns.lineplot(range(1,15),test_scores,marker='o',label='Test Score')"]},{"cell_type":"markdown","metadata":{"_uuid":"1db31455aba31edc524091fa0914743a284034c5","trusted":true},"source":["#### The best result is captured at k = 11 hence 11 is used for the final model"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"277c1bb9c48cca13536ac8ba71604818d323fae0","trusted":true},"outputs":[],"source":["#Setup a knn classifier with k neighbors\n","knn = KNeighborsClassifier(11)\n","\n","knn.fit(X_train,y_train)\n","knn.score(X_test,y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"22878f26662e0a863c48cf43030c9e6ab57d98fc","trusted":true},"outputs":[],"source":["## trying to plot decision boundary "]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"e67d02ae6dbab28b27cfbd968d3717e406de53bf","trusted":true},"outputs":[],"source":["value = 20000\n","width = 20000\n","plot_decision_regions(X.values, y.values, clf=knn, legend=2, \n","                      filler_feature_values={2: value, 3: value, 4: value, 5: value, 6: value, 7: value},\n","                      filler_feature_ranges={2: width, 3: width, 4: width, 5: width, 6: width, 7: width},\n","                      X_highlight=X_test.values)\n","\n","# Adding axes annotations\n","#plt.xlabel('sepal length [cm]')\n","#plt.ylabel('petal length [cm]')\n","plt.title('KNN with Diabetes Data')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"_uuid":"ab1e49d83f39a6ddc780c394d3a052b49508c6ac","trusted":true},"source":["# Model Performance Analysis"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"d09044f60af8405e7334c2062404336d0849e871","trusted":true},"outputs":[],"source":["#import confusion_matrix\n","from sklearn.metrics import confusion_matrix\n","#let us get the predictions using the classifier we had fit above\n","y_pred = knn.predict(X_test)\n","confusion_matrix(y_test,y_pred)\n","pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"cb0b2fc2a33afeed856e2b3cc986ffb9e3e3ae7b","trusted":true},"outputs":[],"source":["y_pred = knn.predict(X_test)\n","from sklearn import metrics\n","cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n","p = sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n","plt.title('Confusion matrix', y=1.1)\n","plt.ylabel('Actual label')\n","plt.xlabel('Predicted label')"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"6ac998149c1f0dd304b807707f0dc44dd2b2ffb3","trusted":true},"outputs":[],"source":["#import classification_report\n","from sklearn.metrics import classification_report\n","print(classification_report(y_test,y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"20b2083d2eaf2fca599eb6f2ef8803be0b1ac5d7","trusted":true},"outputs":[],"source":["from sklearn.metrics import roc_curve\n","y_pred_proba = knn.predict_proba(X_test)[:,1]\n","fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"379eefad0181f1f57ffbb3634ab6d132af17464f","trusted":true},"outputs":[],"source":["plt.plot([0,1],[0,1],'k--')\n","plt.plot(fpr,tpr, label='Knn')\n","plt.xlabel('fpr')\n","plt.ylabel('tpr')\n","plt.title('Knn(n_neighbors=11) ROC curve')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"6c92773e49532f6133b23d511058202bb77ff2cd","trusted":true},"outputs":[],"source":["#Area under ROC curve\n","from sklearn.metrics import roc_auc_score\n","roc_auc_score(y_test,y_pred_proba)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"e369c794253b71d3daa1444fb7d11872fb8a110c","trusted":true},"outputs":[],"source":["#import GridSearchCV\n","from sklearn.model_selection import GridSearchCV\n","#In case of classifier like knn the parameter to be tuned is n_neighbors\n","param_grid = {'n_neighbors':np.arange(1,50)}\n","knn = KNeighborsClassifier()\n","knn_cv= GridSearchCV(knn,param_grid,cv=5)\n","knn_cv.fit(X,y)\n","\n","print(\"Best Score:\" + str(knn_cv.best_score_))\n","print(\"Best Parameters: \" + str(knn_cv.best_params_))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":4}
